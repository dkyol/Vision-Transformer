{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcjSRFELVbNk"
      },
      "source": [
        "# MMAction2 Tutorial\n",
        "\n",
        "Welcome to MMAction2! This is the official colab tutorial for using MMAction2. In this tutorial, you will learn\n",
        "- Perform inference with a MMAction2 recognizer.\n",
        "- Train a new recognizer with a new dataset.\n",
        "\n",
        "\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LqHGkGEVqpm"
      },
      "source": [
        "## Install MMAction2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jAdN1cvcpR0",
        "outputId": "aec6a767-3f81-4dff-8ae0-317407a27c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPwKGzqydnb2",
        "outputId": "f4d937c0-676a-4433-be82-160d91d2417c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0\n",
            "  Using cached torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchaudio==2.0.0\n",
            "  Using cached torchaudio-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (60.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'torchaudio' candidate (version 2.0.0 at https://files.pythonhosted.org/packages/d3/56/50372aaf078d2a3b4082455600875cdefc3ea4a8a0fa8c8c7b215dac3d96/torchaudio-2.0.0-cp311-cp311-manylinux1_x86_64.whl (from https://pypi.org/simple/torchaudio/))\n",
            "Reason for being yanked: Contains an incorrect torch dependency\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.0-cp311-cp311-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 1.0.14 requires torchvision, which is not installed.\n",
            "fastai 2.7.18 requires torchvision>=0.11, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.0 triton-2.0.0\n",
            "2.0.0+cu117\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (if your colab has CUDA 11.8)\n",
        "#%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "!pip install torch==2.0.0 torchaudio==2.0.0\n",
        "\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQSfGpjv2tpN",
        "outputId": "d7230eb6-6823-4172-ffc0-38e54e3a714e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.28.2)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision==0.15.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision==0.15.1) (60.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision==0.15.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision==0.15.1) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision==0.15.1) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchvision==0.15.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchvision==0.15.1) (1.3.0)\n",
            "Downloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "Successfully installed torchvision-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5PAJ4ArzV5Ry",
        "outputId": "93bbcbf6-c453-45b8-f18e-8e7a25b4fc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openmim in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from openmim) (8.1.8)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.11/dist-packages (from openmim) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.11/dist-packages (from openmim) (0.0.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openmim) (2.2.2)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.11/dist-packages (from openmim) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openmim) (2.28.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim) (13.4.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (6.0.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (3.7)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (3.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (4.65.2)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (2024.12.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.17.0)\n",
            "Requirement already satisfied: filelock~=3.14.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (3.14.0)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (2.17.0)\n",
            "Requirement already satisfied: packaging~=24.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (24.2)\n",
            "Requirement already satisfied: setuptools~=60.2.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim) (60.2.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (2.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Requirement already satisfied: mmengine in /usr/local/lib/python3.11/dist-packages (0.10.6)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmengine) (2.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmengine) (1.26.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmengine) (6.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine) (2.5.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmengine) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmengine) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine) (2.18.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmengine) (4.3.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.17.0)\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmcv==2.0.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.0.0-cp311-cp311-manylinux1_x86_64.whl (74.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (0.10.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (6.0.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (2.5.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv==2.0.0) (4.3.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.2.0->mmcv==2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.17.0)\n",
            "Installing collected packages: mmcv\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mmpose 1.3.2 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mmcv-2.0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'%pip install --no-cache-dir -U openmim \\n!mim install mmengine \\n!mim install mmcv==2.0.1 \\n!mim install \"mmdet==3.1.0\" \\n!mim install \"mmpose>=1.1.0\" '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# install MMEngine, MMCV and MMDetection using MIM\n",
        "!pip3 install openmim\n",
        "!mim install mmengine\n",
        "!mim install mmcv==2.0.0\n",
        "\n",
        "# use T4 GPU\n",
        "\n",
        "#Install mmaction2\n",
        "!rm -rf mmaction2\n",
        "!git clone https://github.com/open-mmlab/mmaction2.git -b main\n",
        "#%cd mmaction2\n",
        "\n",
        "#!pip install -e .\n",
        "\n",
        "# Install some optional requirements\n",
        "#!pip install -r requirements/optional.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mmcv\n",
        "print(mmcv.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmhCIYuAvUo5",
        "outputId": "f345395c-501f-4463-b7d4-1043c059a6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No_zZAFpWC-a",
        "outputId": "251da577-5cfc-44c7-e8a6-06393cc462e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu117 True\n",
            "1.2.0\n",
            "11.7\n",
            "GCC 9.3\n",
            "OrderedDict([('sys.platform', 'linux'), ('Python', '3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]'), ('CUDA available', True), ('MUSA available', False), ('numpy_random_seed', 2147483648), ('GPU 0', 'Tesla T4'), ('CUDA_HOME', '/usr/local/cuda'), ('NVCC', 'Cuda compilation tools, release 12.2, V12.2.140'), ('GCC', 'x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0'), ('PyTorch', '2.0.0+cu117'), ('PyTorch compiling details', 'PyTorch built with:\\n  - GCC 9.3\\n  - C++ Version: 201703\\n  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - LAPACK is enabled (usually provided by MKL)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.7\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.5\\n  - Magma 2.6.1\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \\n'), ('TorchVision', '0.15.1+cu117'), ('OpenCV', '4.10.0'), ('MMEngine', '0.10.6')])\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMAction2 installation\n",
        "import mmaction\n",
        "print(mmaction.__version__)\n",
        "\n",
        "# Check MMCV installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check MMEngine installation\n",
        "from mmengine.utils.dl_utils import collect_env\n",
        "print(collect_env())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXf7oV5DWdab"
      },
      "source": [
        "## Perform inference with a MMAction2 recognizer\n",
        "MMAction2 already provides high level APIs to do inference and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64CW6d_AaT-Q",
        "outputId": "c9f0e652-0f59-493d-c700-648e0eae7902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-27 17:42:23--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 163.181.42.240, 163.181.42.241, 163.181.42.242, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|163.181.42.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 97579339 (93M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth’\n",
            "\n",
            "checkpoints/tsn_r50 100%[===================>]  93.06M  31.2MB/s    in 3.0s    \n",
            "\n",
            "2025-01-27 17:42:26 (31.2 MB/s) - ‘checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth’ saved [97579339/97579339]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \\\n",
        "      -O checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls mmaction2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH7M5aPR5n-9",
        "outputId": "b644a3d0-9a95-49ba-97db-5bc258dfe192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CITATION.cff\t   docker\tmmaction\t    README.md\t      resources  tools\n",
            "configs\t\t   docs\t\tmmaction2.egg-info  README_zh-CN.md   setup.cfg\n",
            "dataset-index.yml  LICENSE\tmodel-index.yml     requirements      setup.py\n",
            "demo\t\t   MANIFEST.in\tprojects\t    requirements.txt  tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNZB7NoSabzj",
        "outputId": "2eb7c272-ee61-46c1-c666-7b0bb2e65e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loads checkpoint by local backend from path: checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n"
          ]
        }
      ],
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "from mmengine import Config\n",
        "\n",
        "\n",
        "# Choose to use a config and initialize the recognizer\n",
        "config = 'mmaction2/configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py'\n",
        "config = Config.fromfile(config)\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "# Initialize the recognizer\n",
        "model = init_recognizer(config, checkpoint, device='cuda:0')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "3iJEQO3mI1t2",
        "outputId": "a261fa98-8cf7-42e7-e491-f8fb9b7710da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ec0e57a3-be39-4b1b-a869-a413d59d3738\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ec0e57a3-be39-4b1b-a869-a413d59d3738\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMG_6298.mp4 to IMG_6298.mp4\n",
            "Saving IMG_6297.mp4 to IMG_6297.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEMsBnpHapAn"
      },
      "outputs": [],
      "source": [
        "# Use the recognizer to do inference\n",
        "from operator import itemgetter\n",
        "#video = 'mmaction2/demo/demo.mp4'\n",
        "video = 'IMG_6298.mp4'\n",
        "label = 'mmaction2/tools/data/kinetics/label_map_k400.txt'\n",
        "results = inference_recognizer(model, video)\n",
        "\n",
        "pred_scores = results.pred_score.tolist()\n",
        "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
        "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
        "top5_label = score_sorted[:5]\n",
        "\n",
        "labels = open(label).readlines()\n",
        "labels = [x.strip() for x in labels]\n",
        "results = [(labels[k[0]], k[1]) for k in top5_label]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIyJXqfWathq",
        "outputId": "f4d56357-62ec-471d-a894-b80bb9e2d781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top-5 labels with corresponding scores are:\n",
            "yawning:  0.7484010457992554\n",
            "beatboxing:  0.0796779990196228\n",
            "cracking neck:  0.04732300341129303\n",
            "trimming or shaving beard:  0.01877649314701557\n",
            "sticking tongue out:  0.012985344044864178\n"
          ]
        }
      ],
      "source": [
        "print('The top-5 labels with corresponding scores are:')\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the recognizer to do inference\n",
        "from operator import itemgetter\n",
        "#video = 'mmaction2/demo/demo.mp4'\n",
        "video = 'IMG_6297.mp4'\n",
        "label = 'mmaction2/tools/data/kinetics/label_map_k400.txt'\n",
        "results = inference_recognizer(model, video)\n",
        "\n",
        "pred_scores = results.pred_score.tolist()\n",
        "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
        "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
        "top5_label = score_sorted[:5]\n",
        "\n",
        "labels = open(label).readlines()\n",
        "labels = [x.strip() for x in labels]\n",
        "results = [(labels[k[0]], k[1]) for k in top5_label]"
      ],
      "metadata": {
        "id": "RaZJ7NVuKjY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The top-5 labels with corresponding scores are:')\n",
        "for result in results:\n",
        "    print(f'{result[0]}: ', result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyviktCzKVaI",
        "outputId": "dcfb05f5-65f1-48d1-eb8b-485b4276d2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top-5 labels with corresponding scores are:\n",
            "beatboxing:  0.3087276220321655\n",
            "trimming or shaving beard:  0.21104997396469116\n",
            "cracking neck:  0.17273959517478943\n",
            "filling eyebrows:  0.1142466589808464\n",
            "fixing hair:  0.03378160297870636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat mmaction2/tools/data/kinetics/label_map_k400.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEa7BDxOBvE_",
        "outputId": "a28703f3-0d1f-4a8e-9482-a57253556b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abseiling\n",
            "air drumming\n",
            "answering questions\n",
            "applauding\n",
            "applying cream\n",
            "archery\n",
            "arm wrestling\n",
            "arranging flowers\n",
            "assembling computer\n",
            "auctioning\n",
            "baby waking up\n",
            "baking cookies\n",
            "balloon blowing\n",
            "bandaging\n",
            "barbequing\n",
            "bartending\n",
            "beatboxing\n",
            "bee keeping\n",
            "belly dancing\n",
            "bench pressing\n",
            "bending back\n",
            "bending metal\n",
            "biking through snow\n",
            "blasting sand\n",
            "blowing glass\n",
            "blowing leaves\n",
            "blowing nose\n",
            "blowing out candles\n",
            "bobsledding\n",
            "bookbinding\n",
            "bouncing on trampoline\n",
            "bowling\n",
            "braiding hair\n",
            "breading or breadcrumbing\n",
            "breakdancing\n",
            "brush painting\n",
            "brushing hair\n",
            "brushing teeth\n",
            "building cabinet\n",
            "building shed\n",
            "bungee jumping\n",
            "busking\n",
            "canoeing or kayaking\n",
            "capoeira\n",
            "carrying baby\n",
            "cartwheeling\n",
            "carving pumpkin\n",
            "catching fish\n",
            "catching or throwing baseball\n",
            "catching or throwing frisbee\n",
            "catching or throwing softball\n",
            "celebrating\n",
            "changing oil\n",
            "changing wheel\n",
            "checking tires\n",
            "cheerleading\n",
            "chopping wood\n",
            "clapping\n",
            "clay pottery making\n",
            "clean and jerk\n",
            "cleaning floor\n",
            "cleaning gutters\n",
            "cleaning pool\n",
            "cleaning shoes\n",
            "cleaning toilet\n",
            "cleaning windows\n",
            "climbing a rope\n",
            "climbing ladder\n",
            "climbing tree\n",
            "contact juggling\n",
            "cooking chicken\n",
            "cooking egg\n",
            "cooking on campfire\n",
            "cooking sausages\n",
            "counting money\n",
            "country line dancing\n",
            "cracking neck\n",
            "crawling baby\n",
            "crossing river\n",
            "crying\n",
            "curling hair\n",
            "cutting nails\n",
            "cutting pineapple\n",
            "cutting watermelon\n",
            "dancing ballet\n",
            "dancing charleston\n",
            "dancing gangnam style\n",
            "dancing macarena\n",
            "deadlifting\n",
            "decorating the christmas tree\n",
            "digging\n",
            "dining\n",
            "disc golfing\n",
            "diving cliff\n",
            "dodgeball\n",
            "doing aerobics\n",
            "doing laundry\n",
            "doing nails\n",
            "drawing\n",
            "dribbling basketball\n",
            "drinking\n",
            "drinking beer\n",
            "drinking shots\n",
            "driving car\n",
            "driving tractor\n",
            "drop kicking\n",
            "drumming fingers\n",
            "dunking basketball\n",
            "dying hair\n",
            "eating burger\n",
            "eating cake\n",
            "eating carrots\n",
            "eating chips\n",
            "eating doughnuts\n",
            "eating hotdog\n",
            "eating ice cream\n",
            "eating spaghetti\n",
            "eating watermelon\n",
            "egg hunting\n",
            "exercising arm\n",
            "exercising with an exercise ball\n",
            "extinguishing fire\n",
            "faceplanting\n",
            "feeding birds\n",
            "feeding fish\n",
            "feeding goats\n",
            "filling eyebrows\n",
            "finger snapping\n",
            "fixing hair\n",
            "flipping pancake\n",
            "flying kite\n",
            "folding clothes\n",
            "folding napkins\n",
            "folding paper\n",
            "front raises\n",
            "frying vegetables\n",
            "garbage collecting\n",
            "gargling\n",
            "getting a haircut\n",
            "getting a tattoo\n",
            "giving or receiving award\n",
            "golf chipping\n",
            "golf driving\n",
            "golf putting\n",
            "grinding meat\n",
            "grooming dog\n",
            "grooming horse\n",
            "gymnastics tumbling\n",
            "hammer throw\n",
            "headbanging\n",
            "headbutting\n",
            "high jump\n",
            "high kick\n",
            "hitting baseball\n",
            "hockey stop\n",
            "holding snake\n",
            "hopscotch\n",
            "hoverboarding\n",
            "hugging\n",
            "hula hooping\n",
            "hurdling\n",
            "hurling (sport)\n",
            "ice climbing\n",
            "ice fishing\n",
            "ice skating\n",
            "ironing\n",
            "javelin throw\n",
            "jetskiing\n",
            "jogging\n",
            "juggling balls\n",
            "juggling fire\n",
            "juggling soccer ball\n",
            "jumping into pool\n",
            "jumpstyle dancing\n",
            "kicking field goal\n",
            "kicking soccer ball\n",
            "kissing\n",
            "kitesurfing\n",
            "knitting\n",
            "krumping\n",
            "laughing\n",
            "laying bricks\n",
            "long jump\n",
            "lunge\n",
            "making a cake\n",
            "making a sandwich\n",
            "making bed\n",
            "making jewelry\n",
            "making pizza\n",
            "making snowman\n",
            "making sushi\n",
            "making tea\n",
            "marching\n",
            "massaging back\n",
            "massaging feet\n",
            "massaging legs\n",
            "massaging person's head\n",
            "milking cow\n",
            "mopping floor\n",
            "motorcycling\n",
            "moving furniture\n",
            "mowing lawn\n",
            "news anchoring\n",
            "opening bottle\n",
            "opening present\n",
            "paragliding\n",
            "parasailing\n",
            "parkour\n",
            "passing American football (in game)\n",
            "passing American football (not in game)\n",
            "peeling apples\n",
            "peeling potatoes\n",
            "petting animal (not cat)\n",
            "petting cat\n",
            "picking fruit\n",
            "planting trees\n",
            "plastering\n",
            "playing accordion\n",
            "playing badminton\n",
            "playing bagpipes\n",
            "playing basketball\n",
            "playing bass guitar\n",
            "playing cards\n",
            "playing cello\n",
            "playing chess\n",
            "playing clarinet\n",
            "playing controller\n",
            "playing cricket\n",
            "playing cymbals\n",
            "playing didgeridoo\n",
            "playing drums\n",
            "playing flute\n",
            "playing guitar\n",
            "playing harmonica\n",
            "playing harp\n",
            "playing ice hockey\n",
            "playing keyboard\n",
            "playing kickball\n",
            "playing monopoly\n",
            "playing organ\n",
            "playing paintball\n",
            "playing piano\n",
            "playing poker\n",
            "playing recorder\n",
            "playing saxophone\n",
            "playing squash or racquetball\n",
            "playing tennis\n",
            "playing trombone\n",
            "playing trumpet\n",
            "playing ukulele\n",
            "playing violin\n",
            "playing volleyball\n",
            "playing xylophone\n",
            "pole vault\n",
            "presenting weather forecast\n",
            "pull ups\n",
            "pumping fist\n",
            "pumping gas\n",
            "punching bag\n",
            "punching person (boxing)\n",
            "push up\n",
            "pushing car\n",
            "pushing cart\n",
            "pushing wheelchair\n",
            "reading book\n",
            "reading newspaper\n",
            "recording music\n",
            "riding a bike\n",
            "riding camel\n",
            "riding elephant\n",
            "riding mechanical bull\n",
            "riding mountain bike\n",
            "riding mule\n",
            "riding or walking with horse\n",
            "riding scooter\n",
            "riding unicycle\n",
            "ripping paper\n",
            "robot dancing\n",
            "rock climbing\n",
            "rock scissors paper\n",
            "roller skating\n",
            "running on treadmill\n",
            "sailing\n",
            "salsa dancing\n",
            "sanding floor\n",
            "scrambling eggs\n",
            "scuba diving\n",
            "setting table\n",
            "shaking hands\n",
            "shaking head\n",
            "sharpening knives\n",
            "sharpening pencil\n",
            "shaving head\n",
            "shaving legs\n",
            "shearing sheep\n",
            "shining shoes\n",
            "shooting basketball\n",
            "shooting goal (soccer)\n",
            "shot put\n",
            "shoveling snow\n",
            "shredding paper\n",
            "shuffling cards\n",
            "side kick\n",
            "sign language interpreting\n",
            "singing\n",
            "situp\n",
            "skateboarding\n",
            "ski jumping\n",
            "skiing (not slalom or crosscountry)\n",
            "skiing crosscountry\n",
            "skiing slalom\n",
            "skipping rope\n",
            "skydiving\n",
            "slacklining\n",
            "slapping\n",
            "sled dog racing\n",
            "smoking\n",
            "smoking hookah\n",
            "snatch weight lifting\n",
            "sneezing\n",
            "sniffing\n",
            "snorkeling\n",
            "snowboarding\n",
            "snowkiting\n",
            "snowmobiling\n",
            "somersaulting\n",
            "spinning poi\n",
            "spray painting\n",
            "spraying\n",
            "springboard diving\n",
            "squat\n",
            "sticking tongue out\n",
            "stomping grapes\n",
            "stretching arm\n",
            "stretching leg\n",
            "strumming guitar\n",
            "surfing crowd\n",
            "surfing water\n",
            "sweeping floor\n",
            "swimming backstroke\n",
            "swimming breast stroke\n",
            "swimming butterfly stroke\n",
            "swing dancing\n",
            "swinging legs\n",
            "swinging on something\n",
            "sword fighting\n",
            "tai chi\n",
            "taking a shower\n",
            "tango dancing\n",
            "tap dancing\n",
            "tapping guitar\n",
            "tapping pen\n",
            "tasting beer\n",
            "tasting food\n",
            "testifying\n",
            "texting\n",
            "throwing axe\n",
            "throwing ball\n",
            "throwing discus\n",
            "tickling\n",
            "tobogganing\n",
            "tossing coin\n",
            "tossing salad\n",
            "training dog\n",
            "trapezing\n",
            "trimming or shaving beard\n",
            "trimming trees\n",
            "triple jump\n",
            "tying bow tie\n",
            "tying knot (not on a tie)\n",
            "tying tie\n",
            "unboxing\n",
            "unloading truck\n",
            "using computer\n",
            "using remote controller (not gaming)\n",
            "using segway\n",
            "vault\n",
            "waiting in line\n",
            "walking the dog\n",
            "washing dishes\n",
            "washing feet\n",
            "washing hair\n",
            "washing hands\n",
            "water skiing\n",
            "water sliding\n",
            "watering plants\n",
            "waxing back\n",
            "waxing chest\n",
            "waxing eyebrows\n",
            "waxing legs\n",
            "weaving basket\n",
            "welding\n",
            "whistling\n",
            "windsurfing\n",
            "wrapping present\n",
            "wrestling\n",
            "writing\n",
            "yawning\n",
            "yoga\n",
            "zumba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuZG8kZ2fJ5d"
      },
      "source": [
        "## Train a recognizer on customized dataset\n",
        "\n",
        "To train a new recognizer, there are usually three things to do:\n",
        "1. Support a new dataset\n",
        "2. Modify the config\n",
        "3. Train a new recognizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEFyxChfgiJ"
      },
      "source": [
        "### Support a new dataset\n",
        "\n",
        "In this tutorial, we gives an example to convert the data into the format of existing datasets. Other methods and more advanced usages can be found in the [doc](/docs/tutorials/new_dataset.md)\n",
        "\n",
        "Firstly, let's download a tiny dataset obtained from [Kinetics-400](https://deepmind.com/research/open-source/open-source-datasets/kinetics/). We select 30 videos with their labels as train dataset and 10 videos with their labels as test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjsUj9JzgUlJ",
        "outputId": "96a0e6e9-0dd8-4c07-9fed-22b93d5c1318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'kinetics400_tiny.zip*': No such file or directory\n",
            "--2023-05-15 03:33:27--  https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 163.181.82.216, 163.181.82.218, 163.181.82.213, ...\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|163.181.82.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18308682 (17M) [application/zip]\n",
            "Saving to: ‘kinetics400_tiny.zip’\n",
            "\n",
            "kinetics400_tiny.zi 100%[===================>]  17.46M  32.7MB/s    in 0.5s    \n",
            "\n",
            "2023-05-15 03:33:28 (32.7 MB/s) - ‘kinetics400_tiny.zip’ saved [18308682/18308682]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download, decompress the data\n",
        "!rm kinetics400_tiny.zip*\n",
        "!rm -rf kinetics400_tiny\n",
        "!wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
        "!unzip kinetics400_tiny.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbZ-o7V6hNw4",
        "outputId": "f229f352-1b43-41b7-a374-21404f618581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 43.0 kB of archives.\n",
            "After this operation, 115 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tree amd64 1.8.0-1 [43.0 kB]\n",
            "Fetched 43.0 kB in 1s (48.9 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 122519 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.8.0-1_amd64.deb ...\n",
            "Unpacking tree (1.8.0-1) ...\n",
            "Setting up tree (1.8.0-1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "\u001b[01;34mkinetics400_tiny\u001b[00m\n",
            "├── kinetics_tiny_train_video.txt\n",
            "├── kinetics_tiny_val_video.txt\n",
            "├── \u001b[01;34mtrain\u001b[00m\n",
            "│   ├── 27_CSXByd3s.mp4\n",
            "│   ├── 34XczvTaRiI.mp4\n",
            "│   ├── A-wiliK50Zw.mp4\n",
            "│   ├── D32_1gwq35E.mp4\n",
            "│   ├── D92m0HsHjcQ.mp4\n",
            "│   ├── DbX8mPslRXg.mp4\n",
            "│   ├── FMlSTTpN3VY.mp4\n",
            "│   ├── h10B9SVE-nk.mp4\n",
            "│   ├── h2YqqUhnR34.mp4\n",
            "│   ├── iRuyZSKhHRg.mp4\n",
            "│   ├── IyfILH9lBRo.mp4\n",
            "│   ├── kFC3KY2bOP8.mp4\n",
            "│   ├── LvcFDgCAXQs.mp4\n",
            "│   ├── O46YA8tI530.mp4\n",
            "│   ├── oMrZaozOvdQ.mp4\n",
            "│   ├── oXy-e_P_cAI.mp4\n",
            "│   ├── P5M-hAts7MQ.mp4\n",
            "│   ├── phDqGd0NKoo.mp4\n",
            "│   ├── PnOe3GZRVX8.mp4\n",
            "│   ├── R8HXQkdgKWA.mp4\n",
            "│   ├── RqnKtCEoEcA.mp4\n",
            "│   ├── soEcZZsBmDs.mp4\n",
            "│   ├── TkkZPZHbAKA.mp4\n",
            "│   ├── T_TMNGzVrDk.mp4\n",
            "│   ├── WaS0qwP46Us.mp4\n",
            "│   ├── Wh_YPQdH1Zg.mp4\n",
            "│   ├── WWP5HZJsg-o.mp4\n",
            "│   ├── xGY2dP0YUjA.mp4\n",
            "│   ├── yLC9CtWU5ws.mp4\n",
            "│   └── ZQV4U2KQ370.mp4\n",
            "└── \u001b[01;34mval\u001b[00m\n",
            "    ├── 0pVGiAU6XEA.mp4\n",
            "    ├── AQrbRSnRt8M.mp4\n",
            "    ├── b6Q_b7vgc7Q.mp4\n",
            "    ├── ddvJ6-faICE.mp4\n",
            "    ├── IcLztCtvhb8.mp4\n",
            "    ├── ik4BW3-SCts.mp4\n",
            "    ├── jqRrH30V0k4.mp4\n",
            "    ├── SU_x2LQqSLs.mp4\n",
            "    ├── u4Rm6srmIS8.mp4\n",
            "    └── y5Iu7XkTqV0.mp4\n",
            "\n",
            "2 directories, 42 files\n"
          ]
        }
      ],
      "source": [
        "# Check the directory structure of the tiny data\n",
        "\n",
        "# Install tree first\n",
        "!apt-get -q install tree\n",
        "!tree kinetics400_tiny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTdi6dI0hY3g",
        "outputId": "95f22438-566c-4496-fe0c-50e128b47b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D32_1gwq35E.mp4 0\n",
            "iRuyZSKhHRg.mp4 1\n",
            "oXy-e_P_cAI.mp4 0\n",
            "34XczvTaRiI.mp4 1\n",
            "h2YqqUhnR34.mp4 0\n",
            "O46YA8tI530.mp4 0\n",
            "kFC3KY2bOP8.mp4 1\n",
            "WWP5HZJsg-o.mp4 1\n",
            "phDqGd0NKoo.mp4 1\n",
            "yLC9CtWU5ws.mp4 0\n",
            "27_CSXByd3s.mp4 1\n",
            "IyfILH9lBRo.mp4 1\n",
            "T_TMNGzVrDk.mp4 1\n",
            "TkkZPZHbAKA.mp4 0\n",
            "PnOe3GZRVX8.mp4 1\n",
            "soEcZZsBmDs.mp4 1\n",
            "FMlSTTpN3VY.mp4 1\n",
            "WaS0qwP46Us.mp4 0\n",
            "A-wiliK50Zw.mp4 1\n",
            "oMrZaozOvdQ.mp4 1\n",
            "ZQV4U2KQ370.mp4 0\n",
            "DbX8mPslRXg.mp4 1\n",
            "h10B9SVE-nk.mp4 1\n",
            "P5M-hAts7MQ.mp4 0\n",
            "R8HXQkdgKWA.mp4 0\n",
            "D92m0HsHjcQ.mp4 0\n",
            "RqnKtCEoEcA.mp4 0\n",
            "LvcFDgCAXQs.mp4 0\n",
            "xGY2dP0YUjA.mp4 0\n",
            "Wh_YPQdH1Zg.mp4 0\n"
          ]
        }
      ],
      "source": [
        "# After downloading the data, we need to check the annotation format\n",
        "!cat kinetics400_tiny/kinetics_tiny_train_video.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bq0mxmEi29H"
      },
      "source": [
        "According to the format defined in [`VideoDataset`](./datasets/video_dataset.py), each line indicates a sample video with the filepath and label, which are split with a whitespace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht_DGJA9jQar"
      },
      "source": [
        "### Modify the config\n",
        "\n",
        "In the next step, we need to modify the config for the training.\n",
        "To accelerate the process, we finetune a recognizer using a pre-trained recognizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjCcmCKOjktc"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('./configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc8YhFFGjp3e"
      },
      "source": [
        "Given a config that trains a TSN model on kinetics400-full dataset, we need to modify some values to use it for training TSN on Kinetics400-tiny dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlhu9byjjt-K",
        "outputId": "2d984a1d-93f7-493f-fd77-e19af8285f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=2,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01,\n",
            "        average_clips='prob'),\n",
            "    data_preprocessor=dict(\n",
            "        type='ActionDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        format_shape='NCHW'),\n",
            "    train_cfg=None,\n",
            "    test_cfg=None)\n",
            "train_cfg = dict(\n",
            "    type='EpochBasedTrainLoop', max_epochs=10, val_begin=1, val_interval=1)\n",
            "val_cfg = dict(type='ValLoop')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=100,\n",
            "        by_epoch=True,\n",
            "        milestones=[40, 80],\n",
            "        gamma=0.1)\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(\n",
            "        type='SGD', lr=7.8125e-05, momentum=0.9, weight_decay=0.0001),\n",
            "    clip_grad=dict(max_norm=40, norm_type=2))\n",
            "default_scope = 'mmaction'\n",
            "default_hooks = dict(\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=20, ignore_last=False),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(\n",
            "        type='CheckpointHook', interval=3, save_best='auto', max_keep_ckpts=3),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "log_processor = dict(type='LogProcessor', window_size=20, by_epoch=True)\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
            "log_level = 'INFO'\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "resume = False\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = 'kinetics400_tiny/train/'\n",
            "data_root_val = 'kinetics400_tiny/val/'\n",
            "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
            "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "file_client_args = dict(io_backend='disk')\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=3),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(1, 0.875, 0.75, 0.66),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs')\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=3,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='TenCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs')\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/train/'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=3),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(1, 0.875, 0.75, 0.66),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs')\n",
            "        ]))\n",
            "val_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=3,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs')\n",
            "        ],\n",
            "        test_mode=True))\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='TenCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs')\n",
            "        ],\n",
            "        test_mode=True))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=256)\n",
            "work_dir = './tutorial_exps'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmengine.runner import set_random_seed\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.data_root = 'kinetics400_tiny/train/'\n",
        "cfg.data_root_val = 'kinetics400_tiny/val/'\n",
        "cfg.ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "\n",
        "\n",
        "cfg.test_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.test_dataloader.dataset.data_prefix.video = 'kinetics400_tiny/val/'\n",
        "\n",
        "cfg.train_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
        "cfg.train_dataloader.dataset.data_prefix.video = 'kinetics400_tiny/train/'\n",
        "\n",
        "cfg.val_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
        "cfg.val_dataloader.dataset.data_prefix.video  = 'kinetics400_tiny/val/'\n",
        "\n",
        "\n",
        "# Modify num classes of the model in cls_head\n",
        "cfg.model.cls_head.num_classes = 2\n",
        "# We can use the pre-trained TSN model\n",
        "cfg.load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "\n",
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 16\n",
        "cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 16\n",
        "cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8 / 16\n",
        "cfg.train_cfg.max_epochs = 10\n",
        "\n",
        "cfg.train_dataloader.num_workers = 2\n",
        "cfg.val_dataloader.num_workers = 2\n",
        "cfg.test_dataloader.num_workers = 2\n",
        "\n",
        "# We can initialize the logger for training and have a look\n",
        "# at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tES-qnZ3k38Z"
      },
      "source": [
        "### Train a new recognizer\n",
        "\n",
        "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDBWkdDRk6oz",
        "outputId": "044b9e09-2038-41c9-d5a3-8a74ae11ade2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/15 03:33:34 - mmengine - INFO - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1853452922\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "    PyTorch: 2.0.0+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu118\n",
            "    OpenCV: 4.7.0\n",
            "    MMEngine: 0.7.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: None\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "05/15 03:33:34 - mmengine - INFO - Config:\n",
            "model = dict(\n",
            "    type='Recognizer2D',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        depth=50,\n",
            "        norm_eval=False),\n",
            "    cls_head=dict(\n",
            "        type='TSNHead',\n",
            "        num_classes=2,\n",
            "        in_channels=2048,\n",
            "        spatial_type='avg',\n",
            "        consensus=dict(type='AvgConsensus', dim=1),\n",
            "        dropout_ratio=0.4,\n",
            "        init_std=0.01,\n",
            "        average_clips='prob'),\n",
            "    data_preprocessor=dict(\n",
            "        type='ActionDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        format_shape='NCHW'),\n",
            "    train_cfg=None,\n",
            "    test_cfg=None)\n",
            "train_cfg = dict(\n",
            "    type='EpochBasedTrainLoop', max_epochs=10, val_begin=1, val_interval=1)\n",
            "val_cfg = dict(type='ValLoop')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=100,\n",
            "        by_epoch=True,\n",
            "        milestones=[40, 80],\n",
            "        gamma=0.1)\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    optimizer=dict(\n",
            "        type='SGD', lr=7.8125e-05, momentum=0.9, weight_decay=0.0001),\n",
            "    clip_grad=dict(max_norm=40, norm_type=2))\n",
            "default_scope = 'mmaction'\n",
            "default_hooks = dict(\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=20, ignore_last=False),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(\n",
            "        type='CheckpointHook', interval=3, save_best='auto', max_keep_ckpts=3),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "log_processor = dict(type='LogProcessor', window_size=20, by_epoch=True)\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[dict(type='LocalVisBackend')])\n",
            "log_level = 'INFO'\n",
            "load_from = './checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
            "resume = False\n",
            "dataset_type = 'VideoDataset'\n",
            "data_root = 'kinetics400_tiny/train/'\n",
            "data_root_val = 'kinetics400_tiny/val/'\n",
            "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
            "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
            "file_client_args = dict(io_backend='disk')\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=3),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(\n",
            "        type='MultiScaleCrop',\n",
            "        input_size=224,\n",
            "        scales=(1, 0.875, 0.75, 0.66),\n",
            "        random_crop=False,\n",
            "        max_wh_scale_gap=1),\n",
            "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "    dict(type='Flip', flip_ratio=0.5),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs')\n",
            "]\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=3,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='CenterCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit', io_backend='disk'),\n",
            "    dict(\n",
            "        type='SampleFrames',\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='Resize', scale=(-1, 256)),\n",
            "    dict(type='TenCrop', crop_size=224),\n",
            "    dict(type='FormatShape', input_format='NCHW'),\n",
            "    dict(type='PackActionInputs')\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/train/'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames', clip_len=1, frame_interval=1,\n",
            "                num_clips=3),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(\n",
            "                type='MultiScaleCrop',\n",
            "                input_size=224,\n",
            "                scales=(1, 0.875, 0.75, 0.66),\n",
            "                random_crop=False,\n",
            "                max_wh_scale_gap=1),\n",
            "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
            "            dict(type='Flip', flip_ratio=0.5),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs')\n",
            "        ]))\n",
            "val_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=3,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='CenterCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs')\n",
            "        ],\n",
            "        test_mode=True))\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
            "    dataset=dict(\n",
            "        type='VideoDataset',\n",
            "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
            "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit', io_backend='disk'),\n",
            "            dict(\n",
            "                type='SampleFrames',\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='Resize', scale=(-1, 256)),\n",
            "            dict(type='TenCrop', crop_size=224),\n",
            "            dict(type='FormatShape', input_format='NCHW'),\n",
            "            dict(type='PackActionInputs')\n",
            "        ],\n",
            "        test_mode=True))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "auto_scale_lr = dict(enable=False, base_batch_size=256)\n",
            "work_dir = './tutorial_exps'\n",
            "\n",
            "05/15 03:33:35 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "05/15 03:33:35 - mmengine - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "Loads checkpoint by http backend from path: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/15 03:33:37 - mmengine - INFO - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n",
            "Loads checkpoint by local backend from path: ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
            "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "05/15 03:33:37 - mmengine - INFO - Load checkpoint from ./checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
            "05/15 03:33:37 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "05/15 03:33:37 - mmengine - INFO - Checkpoints will be saved to /content/mmaction2/tutorial_exps.\n",
            "05/15 03:33:41 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:33:41 - mmengine - INFO - Epoch(train)  [1][15/15]  lr: 7.8125e-05  eta: 0:00:31  time: 0.2334  data_time: 0.0793  memory: 2917  grad_norm: 11.9900  loss: 0.6971  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6971\n",
            "05/15 03:33:42 - mmengine - INFO - Epoch(val) [1][5/5]    acc/top1: 0.3000  acc/top5: 1.0000  acc/mean1: 0.3000  data_time: 0.1994  time: 0.2254\n",
            "05/15 03:33:42 - mmengine - INFO - The best checkpoint with 0.3000 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
            "05/15 03:33:46 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:33:46 - mmengine - INFO - Epoch(train)  [2][15/15]  lr: 7.8125e-05  eta: 0:00:29  time: 0.2373  data_time: 0.1369  memory: 961  grad_norm: 12.4935  loss: 0.7158  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7158\n",
            "05/15 03:33:48 - mmengine - INFO - Epoch(val) [2][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.2692  time: 0.3006\n",
            "05/15 03:33:48 - mmengine - INFO - The previous best checkpoint /content/mmaction2/tutorial_exps/best_acc_top1_epoch_1.pth is removed\n",
            "05/15 03:33:48 - mmengine - INFO - The best checkpoint with 0.7000 acc/top1 at 2 epoch is saved to best_acc_top1_epoch_2.pth.\n",
            "05/15 03:33:51 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:33:51 - mmengine - INFO - Epoch(train)  [3][15/15]  lr: 7.8125e-05  eta: 0:00:24  time: 0.2112  data_time: 0.1163  memory: 961  grad_norm: 13.4063  loss: 0.7338  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7338\n",
            "05/15 03:33:51 - mmengine - INFO - Saving checkpoint at 3 epochs\n",
            "05/15 03:33:53 - mmengine - INFO - Epoch(val) [3][5/5]    acc/top1: 0.4000  acc/top5: 1.0000  acc/mean1: 0.4000  data_time: 0.1669  time: 0.1906\n",
            "05/15 03:33:56 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:33:56 - mmengine - INFO - Epoch(train)  [4][15/15]  lr: 7.8125e-05  eta: 0:00:19  time: 0.1750  data_time: 0.0907  memory: 961  grad_norm: 12.4322  loss: 0.6894  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6894\n",
            "05/15 03:33:57 - mmengine - INFO - Epoch(val) [4][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.1791  time: 0.2030\n",
            "05/15 03:34:00 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:34:00 - mmengine - INFO - Epoch(train)  [5][15/15]  lr: 7.8125e-05  eta: 0:00:16  time: 0.2016  data_time: 0.1155  memory: 961  grad_norm: 11.5982  loss: 0.6940  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6940\n",
            "05/15 03:34:02 - mmengine - INFO - Epoch(val) [5][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.3145  time: 0.3455\n",
            "05/15 03:34:05 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:34:05 - mmengine - INFO - Epoch(train)  [6][15/15]  lr: 7.8125e-05  eta: 0:00:13  time: 0.2366  data_time: 0.1440  memory: 961  grad_norm: 12.0952  loss: 0.6667  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6667\n",
            "05/15 03:34:05 - mmengine - INFO - Saving checkpoint at 6 epochs\n",
            "05/15 03:34:08 - mmengine - INFO - Epoch(val) [6][5/5]    acc/top1: 0.6000  acc/top5: 1.0000  acc/mean1: 0.6000  data_time: 0.2172  time: 0.2403\n",
            "05/15 03:34:10 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:34:10 - mmengine - INFO - Epoch(train)  [7][15/15]  lr: 7.8125e-05  eta: 0:00:09  time: 0.1784  data_time: 0.0942  memory: 961  grad_norm: 12.4209  loss: 0.6570  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6570\n",
            "05/15 03:34:11 - mmengine - INFO - Epoch(val) [7][5/5]    acc/top1: 0.9000  acc/top5: 1.0000  acc/mean1: 0.9000  data_time: 0.1898  time: 0.2118\n",
            "05/15 03:34:11 - mmengine - INFO - The previous best checkpoint /content/mmaction2/tutorial_exps/best_acc_top1_epoch_2.pth is removed\n",
            "05/15 03:34:12 - mmengine - INFO - The best checkpoint with 0.9000 acc/top1 at 7 epoch is saved to best_acc_top1_epoch_7.pth.\n",
            "05/15 03:34:15 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:34:15 - mmengine - INFO - Epoch(train)  [8][15/15]  lr: 7.8125e-05  eta: 0:00:06  time: 0.2073  data_time: 0.1220  memory: 961  grad_norm: 11.4271  loss: 0.6241  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6241\n",
            "05/15 03:34:17 - mmengine - INFO - Epoch(val) [8][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.3497  time: 0.3890\n",
            "05/15 03:34:17 - mmengine - INFO - The previous best checkpoint /content/mmaction2/tutorial_exps/best_acc_top1_epoch_7.pth is removed\n",
            "05/15 03:34:18 - mmengine - INFO - The best checkpoint with 1.0000 acc/top1 at 8 epoch is saved to best_acc_top1_epoch_8.pth.\n",
            "05/15 03:34:21 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:34:21 - mmengine - INFO - Epoch(train)  [9][15/15]  lr: 7.8125e-05  eta: 0:00:03  time: 0.2309  data_time: 0.1390  memory: 961  grad_norm: 12.3066  loss: 0.6451  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6451\n",
            "05/15 03:34:21 - mmengine - INFO - Saving checkpoint at 9 epochs\n",
            "05/15 03:34:23 - mmengine - INFO - Epoch(val) [9][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.2023  time: 0.2256\n",
            "05/15 03:34:26 - mmengine - INFO - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20230515_033334\n",
            "05/15 03:34:26 - mmengine - INFO - Epoch(train) [10][15/15]  lr: 7.8125e-05  eta: 0:00:00  time: 0.1733  data_time: 0.0951  memory: 961  grad_norm: 11.1461  loss: 0.5931  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5931\n",
            "05/15 03:34:26 - mmengine - INFO - Saving checkpoint at 10 epochs\n",
            "05/15 03:34:27 - mmengine - INFO - Epoch(val) [10][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.1836  time: 0.2048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Recognizer2D(\n",
              "  (data_preprocessor): ActionDataPreprocessor()\n",
              "  (backbone): ResNet(\n",
              "    (conv1): ConvModule(\n",
              "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (activate): ReLU(inplace=True)\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): ConvModule(\n",
              "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): ConvModule(\n",
              "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv2): ConvModule(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (activate): ReLU(inplace=True)\n",
              "        )\n",
              "        (conv3): ConvModule(\n",
              "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls_head): TSNHead(\n",
              "    (loss_cls): CrossEntropyLoss()\n",
              "    (consensus): AvgConsensus()\n",
              "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (dropout): Dropout(p=0.4, inplace=False)\n",
              "    (fc_cls): Linear(in_features=2048, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import mmengine\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "# Create work_dir\n",
        "mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "\n",
        "# build the runner from config\n",
        "runner = Runner.from_cfg(cfg)\n",
        "\n",
        "# start training\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdSd7oTLlxIf"
      },
      "source": [
        "### Understand the log\n",
        "From the log, we can have a basic understanding the training process and know how well the recognizer is trained.\n",
        "\n",
        "Firstly, the ResNet-50 backbone pre-trained on ImageNet is loaded, this is a common practice since training from scratch is more cost. The log shows that all the weights of the ResNet-50 backbone are loaded except the `fc.bias` and `fc.weight`.\n",
        "\n",
        "Second, since the dataset we are using is small, we loaded a TSN model and finetune it for action recognition.\n",
        "The original TSN is trained on original Kinetics-400 dataset which contains 400 classes but Kinetics-400 Tiny dataset only have 2 classes. Therefore, the last FC layer of the pre-trained TSN for classification has different weight shape and is not used.\n",
        "\n",
        "Third, after training, the recognizer is evaluated by the default evaluation. The results show that the recognizer achieves 100% top1 accuracy and 100% top5 accuracy on the val dataset,\n",
        "\n",
        "Not bad!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryVoSfZVmogw"
      },
      "source": [
        "## Test the trained recognizer\n",
        "\n",
        "After finetuning the recognizer, let's check the prediction results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyY3hCMwyTct",
        "outputId": "34fbbdc5-b9fd-4fd2-8030-3ba56b10adbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/15 03:34:36 - mmengine - INFO - Epoch(test) [10/10]    acc/top1: 0.9000  acc/top5: 1.0000  acc/mean1: 0.9000  data_time: 0.0586  time: 0.7817\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc/top1': 0.9, 'acc/top5': 1.0, 'acc/mean1': 0.9}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "runner.test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "189c342a4747645665e89db23000ac4d4edb7a87c4cd0b2f881610f468fb778d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}